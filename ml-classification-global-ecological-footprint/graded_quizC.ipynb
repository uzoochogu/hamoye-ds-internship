{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution to some questions from Hamoye Stage C Quiz.\n",
    "\n",
    "Check README.md for more information on the data\n",
    "\n",
    "Link to Dataset: https://archive.ics.uci.edu/ml/datasets/Electrical+Grid+Stability+Simulated+Data+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\myMLenv\\lib\\site-packages\\dask\\dataframe\\utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "#Import necessary Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import train_test_split to split the dataset into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# import accuracy_score, confusion_matrix, classification_report & f1_score to perform cross validation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "\n",
    "# import cross_val_score, RandomizedSearchCV, KFold & StratifiedKFold for measuring performance\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, KFold, StratifiedKFold\n",
    "\n",
    "# import RandomForestClassifier, ExtraTreesClassifier to create and select  Classifier model\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "# import XGBClassifier for Gradient boost classifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "# import LigtGBM Classifier\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset\n",
    "\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Electrical+Grid+Stability+Simulated+Data+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>-0.005957</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3  0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4  3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "\n",
       "         p4        g1        g2        g3        g4      stab     stabf  \n",
       "0 -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347  unstable  \n",
       "1 -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957    stable  \n",
       "2 -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471  unstable  \n",
       "3 -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871  unstable  \n",
       "4 -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860  unstable  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset is stored locally\n",
    "\n",
    "eco_footprint = pd.read_csv(\"Data_for_UCI_named.csv\")\n",
    "eco_footprint.head() #Let's have a peek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a description of statistical dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.250000</td>\n",
       "      <td>5.250001</td>\n",
       "      <td>5.250004</td>\n",
       "      <td>5.249997</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.015731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.742548</td>\n",
       "      <td>2.742549</td>\n",
       "      <td>2.742549</td>\n",
       "      <td>2.742556</td>\n",
       "      <td>0.752160</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.274256</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.036919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.500793</td>\n",
       "      <td>0.500141</td>\n",
       "      <td>0.500788</td>\n",
       "      <td>0.500473</td>\n",
       "      <td>1.582590</td>\n",
       "      <td>-1.999891</td>\n",
       "      <td>-1.999945</td>\n",
       "      <td>-1.999926</td>\n",
       "      <td>0.050009</td>\n",
       "      <td>0.050053</td>\n",
       "      <td>0.050054</td>\n",
       "      <td>0.050028</td>\n",
       "      <td>-0.080760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.874892</td>\n",
       "      <td>2.875140</td>\n",
       "      <td>2.875522</td>\n",
       "      <td>2.874950</td>\n",
       "      <td>3.218300</td>\n",
       "      <td>-1.624901</td>\n",
       "      <td>-1.625025</td>\n",
       "      <td>-1.624960</td>\n",
       "      <td>0.287521</td>\n",
       "      <td>0.287552</td>\n",
       "      <td>0.287514</td>\n",
       "      <td>0.287494</td>\n",
       "      <td>-0.015557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.250004</td>\n",
       "      <td>5.249981</td>\n",
       "      <td>5.249979</td>\n",
       "      <td>5.249734</td>\n",
       "      <td>3.751025</td>\n",
       "      <td>-1.249966</td>\n",
       "      <td>-1.249974</td>\n",
       "      <td>-1.250007</td>\n",
       "      <td>0.525009</td>\n",
       "      <td>0.525003</td>\n",
       "      <td>0.525015</td>\n",
       "      <td>0.525002</td>\n",
       "      <td>0.017142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.624690</td>\n",
       "      <td>7.624893</td>\n",
       "      <td>7.624948</td>\n",
       "      <td>7.624838</td>\n",
       "      <td>4.282420</td>\n",
       "      <td>-0.874977</td>\n",
       "      <td>-0.875043</td>\n",
       "      <td>-0.875065</td>\n",
       "      <td>0.762435</td>\n",
       "      <td>0.762490</td>\n",
       "      <td>0.762440</td>\n",
       "      <td>0.762433</td>\n",
       "      <td>0.044878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.999469</td>\n",
       "      <td>9.999837</td>\n",
       "      <td>9.999450</td>\n",
       "      <td>9.999443</td>\n",
       "      <td>5.864418</td>\n",
       "      <td>-0.500108</td>\n",
       "      <td>-0.500072</td>\n",
       "      <td>-0.500025</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>0.109403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tau1          tau2          tau3          tau4            p1  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       5.250000      5.250001      5.250004      5.249997      3.750000   \n",
       "std        2.742548      2.742549      2.742549      2.742556      0.752160   \n",
       "min        0.500793      0.500141      0.500788      0.500473      1.582590   \n",
       "25%        2.874892      2.875140      2.875522      2.874950      3.218300   \n",
       "50%        5.250004      5.249981      5.249979      5.249734      3.751025   \n",
       "75%        7.624690      7.624893      7.624948      7.624838      4.282420   \n",
       "max        9.999469      9.999837      9.999450      9.999443      5.864418   \n",
       "\n",
       "                 p2            p3            p4            g1            g2  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean      -1.250000     -1.250000     -1.250000      0.525000      0.525000   \n",
       "std        0.433035      0.433035      0.433035      0.274256      0.274255   \n",
       "min       -1.999891     -1.999945     -1.999926      0.050009      0.050053   \n",
       "25%       -1.624901     -1.625025     -1.624960      0.287521      0.287552   \n",
       "50%       -1.249966     -1.249974     -1.250007      0.525009      0.525003   \n",
       "75%       -0.874977     -0.875043     -0.875065      0.762435      0.762490   \n",
       "max       -0.500108     -0.500072     -0.500025      0.999937      0.999944   \n",
       "\n",
       "                 g3            g4          stab  \n",
       "count  10000.000000  10000.000000  10000.000000  \n",
       "mean       0.525000      0.525000      0.015731  \n",
       "std        0.274255      0.274255      0.036919  \n",
       "min        0.050054      0.050028     -0.080760  \n",
       "25%        0.287514      0.287494     -0.015557  \n",
       "50%        0.525015      0.525002      0.017142  \n",
       "75%        0.762440      0.762433      0.044878  \n",
       "max        0.999982      0.999930      0.109403  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eco_footprint.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   tau1    10000 non-null  float64\n",
      " 1   tau2    10000 non-null  float64\n",
      " 2   tau3    10000 non-null  float64\n",
      " 3   tau4    10000 non-null  float64\n",
      " 4   p1      10000 non-null  float64\n",
      " 5   p2      10000 non-null  float64\n",
      " 6   p3      10000 non-null  float64\n",
      " 7   p4      10000 non-null  float64\n",
      " 8   g1      10000 non-null  float64\n",
      " 9   g2      10000 non-null  float64\n",
      " 10  g3      10000 non-null  float64\n",
      " 11  g4      10000 non-null  float64\n",
      " 12  stab    10000 non-null  float64\n",
      " 13  stabf   10000 non-null  object \n",
      "dtypes: float64(13), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#info\n",
    "eco_footprint.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 13 numerical variables execpt stabf which is categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tau1     0\n",
       "tau2     0\n",
       "tau3     0\n",
       "tau4     0\n",
       "p1       0\n",
       "p2       0\n",
       "p3       0\n",
       "p4       0\n",
       "g1       0\n",
       "g2       0\n",
       "g3       0\n",
       "g4       0\n",
       "stab     0\n",
       "stabf    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eco_footprint.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing data in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As instructed the \"stab\" column is droppedd. This also helps since we are creating a binary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop stab column\n",
    "eco_footprint.drop('stab', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the Labels in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unstable    6380\n",
       "stable      3620\n",
       "Name: stabf, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count unique values of stabf\n",
    "eco_footprint['stabf'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature variables\n",
    "X = eco_footprint.drop('stabf', axis = 1)\n",
    "# create target variable\n",
    "y = eco_footprint['stabf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the Dataset into a 80-20 train-test split using random state of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the Data (Test and Train sets) using the Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise X_train \n",
    "normalized_X_train = pd.DataFrame(StandardScaler().fit_transform(X_train), columns = X_train.columns)\n",
    "\n",
    "\n",
    "# normalise X_test \n",
    "normalized_X_test = pd.DataFrame(StandardScaler().fit_transform(X_test), columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the following models:\n",
    "\n",
    "1. RandomForestClassifier()\n",
    "2. XGBClassifier()\n",
    "3. LGBMClassifier()\n",
    "4. ExtraTreesClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of Models used\n",
    "\n",
    "\n",
    "#random forest classifier\n",
    "forest_clf = RandomForestClassifier(random_state=1)\n",
    "\n",
    "#extreme gradient boosting model\n",
    "xgbc = XGBClassifier(max_depth=3, learning_rate=0.1, random_state=1)\n",
    "\n",
    "\n",
    "#light gradient boosting model\n",
    "lgbmc = LGBMClassifier(random_state=1)\n",
    "\n",
    "\n",
    "#extra trees Classifier\n",
    "extc = ExtraTreesClassifier(random_state=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train model\n",
    "def model_train(model, X = normalized_X_train, y = y_train):\n",
    "    return model.fit(X, y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\myMLenv\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:47:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(random_state=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train models\n",
    "\n",
    "# random forest classifier\n",
    "model_train(forest_clf)\n",
    "\n",
    "# extreme boosting model\n",
    "model_train(xgbc)\n",
    "\n",
    "# light gradient boosting model\n",
    "model_train(lgbmc)\n",
    "\n",
    "# extra trees classifier\n",
    "model_train(extc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "\n",
    "Using the ExtraTreesClassifier as your estimator with cv=5, n_iter=10, scoring = 'accuracy', n_jobs = -1, verbose = 1 and random_state = 1. What are the best hyperparameters from the randomized search CV?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters (Obtained from the question)\n",
    "\n",
    "# the number of trees in the forest/number of boosting rounds\n",
    "n_estimators = [50, 100, 300, 500, 1000]\n",
    "\n",
    "# the minimum number of samples required to split an internal node\n",
    "min_samples_split = [2, 3, 5, 7, 9]\n",
    "\n",
    "# the minimum number of samples required to be at a leaf node\n",
    "min_samples_leaf = [1, 2, 4, 6, 8]\n",
    "\n",
    "# the number of features to consider when looking for the best split\n",
    "max_features = ['auto', 'sqrt', 'log2', None] \n",
    "\n",
    "# grid hyperparameter\n",
    "params = {'n_estimators': n_estimators,\n",
    "                       'min_samples_leaf': min_samples_leaf,\n",
    "                       'min_samples_split': min_samples_split,\n",
    "                       'max_features': max_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 8,\n",
       " 'max_features': None}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radomized_cv = RandomizedSearchCV(extc, params,cv = 5, n_iter = 10, \n",
    "                                  scoring = 'accuracy', n_jobs = -1, verbose = 1, random_state = 1)\n",
    "search_param = model_train(radomized_cv)\n",
    "search_param.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Question: \n",
    "\n",
    "Find the feature importance using the optimal ExtraTreesClassifier model. Which features are the most and least important respectively?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Feature Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p1</td>\n",
       "      <td>0.039507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p2</td>\n",
       "      <td>0.040371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p4</td>\n",
       "      <td>0.040579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p3</td>\n",
       "      <td>0.040706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g1</td>\n",
       "      <td>0.089783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>g2</td>\n",
       "      <td>0.093676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g4</td>\n",
       "      <td>0.094019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>g3</td>\n",
       "      <td>0.096883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tau3</td>\n",
       "      <td>0.113169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tau4</td>\n",
       "      <td>0.115466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tau1</td>\n",
       "      <td>0.117397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tau2</td>\n",
       "      <td>0.118445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Features  Feature Importance\n",
       "0        p1            0.039507\n",
       "1        p2            0.040371\n",
       "2        p4            0.040579\n",
       "3        p3            0.040706\n",
       "4        g1            0.089783\n",
       "5        g2            0.093676\n",
       "6        g4            0.094019\n",
       "7        g3            0.096883\n",
       "8      tau3            0.113169\n",
       "9      tau4            0.115466\n",
       "10     tau1            0.117397\n",
       "11     tau2            0.118445"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp = pd.Series(extc.feature_importances_, normalized_X_train.columns).sort_values()\n",
    "feature_imp_df = pd.DataFrame(feature_imp).reset_index()\n",
    "feature_imp_df.columns = ['Features', \"Feature Importance\"]\n",
    "feature_imp_df[\"Feature Importance\"].round(3)\n",
    "\n",
    "feature_imp_df\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that tau2 has the highest importance and p1 has the least feature importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Question:\n",
    "\n",
    "You are working on a spam classification system using regularized logistic regression. “Spam” is a positive class (y = 1) and “not spam” is the negative class (y = 0). You have trained your classifier and there are n = 1700 examples in the test set. The confusion matrix of predicted class vs. actual class is:\n",
    "\n",
    "|                     | Actual: Spam | Actual: Not Spam| \n",
    "| -----------         | -----------  | ----------      |\n",
    "| Predicted: Spam     | 255          |  1380           |\n",
    "| Predicted: Not Spam | 45           | 20              |\n",
    "\n",
    "\n",
    "\n",
    "What is the F1 score of this classifier?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The F1 score of the classifier is 0.2636'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the confusion matrix\n",
    "TP, FP, FN, TN = 255, 1380, 45, 20\n",
    "pricission = TP/(TP + FP)\n",
    "accuracy = TP/(TP + FN)\n",
    "F1_score = round((2 * pricission * accuracy)/(pricission + accuracy), 4)\n",
    "f'The F1 score of the classifier is {F1_score}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of the Classifiers on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for classification report and accuracy\n",
    "def model_accuracy(model, X_train = normalized_X_train, y_train = y_train, X_test = normalized_X_test):\n",
    "    \"\"\"\n",
    "    function for classification report and accuracy\n",
    "    \n",
    "    return: Void    \n",
    "    \"\"\"    \n",
    "    model.fit(X_train, y_train)                                 # train model\n",
    "    y_pred = model.predict(X_test)                              # test model\n",
    "    print(f'Classification report for {model} is:')\n",
    "    print(classification_report(y_test, y_pred, digits = 5))    # print classification_report\n",
    "    print('')\n",
    "    accuracy = round(accuracy_score(y_test, y_pred), 4)         # accuracy of model\n",
    "    print(f'Accuracy is {accuracy}')                            # prints model accuracy\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Question:\n",
    "\n",
    "What is the accuracy on the test set using the random forest classifier? In 4 decimal places.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for RandomForestClassifier(random_state=1) is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable    0.91765   0.87640   0.89655       712\n",
      "    unstable    0.93333   0.95652   0.94479      1288\n",
      "\n",
      "    accuracy                        0.92800      2000\n",
      "   macro avg    0.92549   0.91646   0.92067      2000\n",
      "weighted avg    0.92775   0.92800   0.92761      2000\n",
      "\n",
      "\n",
      "Accuracy is 0.928\n"
     ]
    }
   ],
   "source": [
    "# random forest classifier(rfc) accuracy\n",
    "model_accuracy(forest_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "\n",
    "What is the accuracy on the test set using the XGboost classifier? In 4 decimal places.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:48:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\myMLenv\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
      "              max_depth=3, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=1,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None) is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable    0.92438   0.84129   0.88088       712\n",
      "    unstable    0.91642   0.96196   0.93864      1288\n",
      "\n",
      "    accuracy                        0.91900      2000\n",
      "   macro avg    0.92040   0.90162   0.90976      2000\n",
      "weighted avg    0.91925   0.91900   0.91808      2000\n",
      "\n",
      "\n",
      "Accuracy is 0.919\n"
     ]
    }
   ],
   "source": [
    "#XGBoost classifier accuracy \n",
    "model_accuracy(xgbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "\n",
    "What is the accuracy on the test set using the LGBM classifier? In 4 decimal places.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for LGBMClassifier(random_state=1) is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable    0.92576   0.89326   0.90922       712\n",
      "    unstable    0.94212   0.96040   0.95117      1288\n",
      "\n",
      "    accuracy                        0.93650      2000\n",
      "   macro avg    0.93394   0.92683   0.93020      2000\n",
      "weighted avg    0.93630   0.93650   0.93624      2000\n",
      "\n",
      "\n",
      "Accuracy is 0.9365\n"
     ]
    }
   ],
   "source": [
    "#LGBM accuracy \n",
    "model_accuracy(lgbmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "\n",
    "Train a new ExtraTreesClassifier Model with the new Hyperparameters from the RandomizedSearchCV (with random_state = 1). Is the accuracy of the new optimal model higher or lower than the initial ExtraTreesClassifier model with no hyperparameter tuning?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for ExtraTreesClassifier(random_state=1) is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable    0.94063   0.84551   0.89053       712\n",
      "    unstable    0.91912   0.97050   0.94411      1288\n",
      "\n",
      "    accuracy                        0.92600      2000\n",
      "   macro avg    0.92987   0.90800   0.91732      2000\n",
      "weighted avg    0.92677   0.92600   0.92504      2000\n",
      "\n",
      "\n",
      "Accuracy is 0.926\n"
     ]
    }
   ],
   "source": [
    "# extra trees classifier model(extc) accuracy with no hyperparameter tuning\n",
    "model_accuracy(extc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.9285\n"
     ]
    }
   ],
   "source": [
    "# we'll use best parameters to train the dataset using extra trees classifier model\n",
    "tuned_extc = ExtraTreesClassifier(**search_param.best_params_, random_state = 1)\n",
    "tuned_extc.fit(normalized_X_train, y_train)\n",
    "tuned_y_pred = tuned_extc.predict(normalized_X_test)\n",
    "accuracy = round(accuracy_score(y_test, tuned_y_pred), 4)\n",
    "print(f'Accuracy is {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore the accuracy of the new tuned model is higher than the first ExtraTressClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: So far the LightGBM has the Best accuracy on the test set. (acc = 0.9365)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d18c3d99e326808c0ea9776033fedd1fe4d7964bdcf2f58ebb2d89bb2832f5d0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('myMLenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
