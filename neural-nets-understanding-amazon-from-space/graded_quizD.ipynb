{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Stage D Submission: Understanding the Amazon from Space"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["import numpy as np \n","import pandas as pd #data processing(reading csv file)"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_name</th>\n","      <th>tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train_0</td>\n","      <td>haze primary</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>train_1</td>\n","      <td>agriculture clear primary water</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>train_2</td>\n","      <td>clear primary</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train_3</td>\n","      <td>clear primary</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>train_4</td>\n","      <td>agriculture clear habitation primary road</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  image_name                                       tags\n","0    train_0                               haze primary\n","1    train_1            agriculture clear primary water\n","2    train_2                              clear primary\n","3    train_3                              clear primary\n","4    train_4  agriculture clear habitation primary road"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["#Reading the train classes that contains the image names and tags from the directory\n","train_classes = pd.read_csv('../input/planets-dataset/planet/planet/train_classes.csv')\n","train_classes.head()"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['blooming', 'agriculture', 'blow_down', 'clear', 'selective_logging', 'conventional_mine', 'road', 'partly_cloudy', 'water', 'cloudy', 'artisinal_mine', 'slash_burn', 'cultivation', 'bare_ground', 'habitation', 'haze', 'primary']\n"]}],"source":["#define a function to split the tags and store a set of the tags in a variable called labels.\n","#set is used to return the unique labels in the tags\n","labels = set()\n","def splitting_tags(tags):\n","    for tag in tags.split():\n","        labels.add(tag)\n","\n","#we redefine the train_classes by creating a copy of it so as not to overwrite the existing one. \n","#so a copy of the train classes is stored in the variable train_classes1, we convert labels which is a set to a list.\n","train_classes1 = train_classes.copy()\n","train_classes1['tags'].apply(splitting_tags)\n","labels = list(labels)\n","print(labels)"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[],"source":["#assert  that the length of the dataframe is the same as the shape\n","assert len(train_classes1['image_name'].unique()) == train_classes1.shape[0]"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_name</th>\n","      <th>tags</th>\n","      <th>blooming</th>\n","      <th>agriculture</th>\n","      <th>blow_down</th>\n","      <th>clear</th>\n","      <th>selective_logging</th>\n","      <th>conventional_mine</th>\n","      <th>road</th>\n","      <th>partly_cloudy</th>\n","      <th>water</th>\n","      <th>cloudy</th>\n","      <th>artisinal_mine</th>\n","      <th>slash_burn</th>\n","      <th>cultivation</th>\n","      <th>bare_ground</th>\n","      <th>habitation</th>\n","      <th>haze</th>\n","      <th>primary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train_0.jpg</td>\n","      <td>haze primary</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>train_1.jpg</td>\n","      <td>agriculture clear primary water</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>train_2.jpg</td>\n","      <td>clear primary</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train_3.jpg</td>\n","      <td>clear primary</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>train_4.jpg</td>\n","      <td>agriculture clear habitation primary road</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    image_name                                       tags  blooming  \\\n","0  train_0.jpg                               haze primary         0   \n","1  train_1.jpg            agriculture clear primary water         0   \n","2  train_2.jpg                              clear primary         0   \n","3  train_3.jpg                              clear primary         0   \n","4  train_4.jpg  agriculture clear habitation primary road         0   \n","\n","   agriculture  blow_down  clear  selective_logging  conventional_mine  road  \\\n","0            0          0      0                  0                  0     0   \n","1            1          0      1                  0                  0     0   \n","2            0          0      1                  0                  0     0   \n","3            0          0      1                  0                  0     0   \n","4            1          0      1                  0                  0     1   \n","\n","   partly_cloudy  water  cloudy  artisinal_mine  slash_burn  cultivation  \\\n","0              0      0       0               0           0            0   \n","1              0      1       0               0           0            0   \n","2              0      0       0               0           0            0   \n","3              0      0       0               0           0            0   \n","4              0      0       0               0           0            0   \n","\n","   bare_ground  habitation  haze  primary  \n","0            0           0     1        1  \n","1            0           0     0        1  \n","2            0           0     0        1  \n","3            0           0     0        1  \n","4            0           1     0        1  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["##One hot encoding is performed on the labels in train classes\n","for tag in labels:\n","    train_classes1[tag] = train_classes1['tags'].apply(lambda x: 1 if tag in x.split() else 0)\n","    \n","## adding .jpg extension to the column image_name so as to have same name format as the image files\n","train_classes1['image_name'] = train_classes1['image_name'].apply(lambda x: '{}.jpg'.format(x))\n","train_classes1.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["#importing tensorflow libraries for training the dataset\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, BatchNormalization, Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import Dropout, Flatten\n","from tensorflow.keras.optimizers import Adam, SGD\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["#defining the columns, that is the labels that were newly added to the train_classes via hot encoding.\n","columns = list(train_classes1.columns[2:]) #from index 2 to the end defines the columns"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["['blooming',\n"," 'agriculture',\n"," 'blow_down',\n"," 'clear',\n"," 'selective_logging',\n"," 'conventional_mine',\n"," 'road',\n"," 'partly_cloudy',\n"," 'water',\n"," 'cloudy',\n"," 'artisinal_mine',\n"," 'slash_burn',\n"," 'cultivation',\n"," 'bare_ground',\n"," 'habitation',\n"," 'haze',\n"," 'primary']"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["columns"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[],"source":["#define a function for fbeta scoring\n","def fbeta(y_true, y_pred, beta = 2, epsilon = 1e-4):\n","    \n","    beta_squared = beta**2\n","    \n","    y_true = tf.cast(y_true, tf.float32)\n","    y_pred = tf.cast(tf.greater(tf.cast(y_pred, tf.float32), tf.constant(0.5)), tf.float32)\n","    \n","    tp = tf.reduce_sum(y_true * y_pred, axis = 1)\n","    fp = tf.reduce_sum(y_pred, axis = 1) - tp\n","    fn = tf.reduce_sum(y_true, axis = 1) - tp\n","    \n","    precision = tp/(tp+fp+epsilon)\n","    recall = tp/(tp+fn+epsilon)\n","    \n","    fb = (1+beta_squared)*precision*recall / (beta_squared*precision+recall+epsilon)\n","    return fb"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[],"source":["#define a function for accuracy for multi_label classification\n","def multi_label_acc(y_true, y_pred, epsilon = 1e-4):\n","    \n","    y_true = tf.cast(y_true, tf.float32)\n","    y_pred = tf.cast(tf.greater(tf.cast(y_pred, tf.float32), tf.constant(0.5)), tf.float32)\n","    \n","    tp = tf.reduce_sum(y_true * y_pred, axis = 1)\n","    fp = tf.reduce_sum(y_pred, axis = 1) - tp\n","    fn = tf.reduce_sum(y_true, axis = 1) - tp\n","    \n","    y_true = tf.cast(y_true, tf.bool)\n","    y_pred = tf.cast(y_pred, tf.bool)\n","        \n","    tn = tf.reduce_sum(tf.cast(tf.logical_not(y_true), tf.float32) * tf.cast(tf.logical_not(y_pred), tf.float32), \n","                       axis = 1)\n","    return (tp+tn)/(tp+tn+fp+fn+epsilon)"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[],"source":["#defining our model using a function build_model()\n","def build_model():\n","    model = Sequential()\n","    model.add(BatchNormalization(input_shape=(128, 128, 3)))\n","    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n","    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.2))\n","\n","    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n","    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.2))\n","\n","    model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n","    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.2))\n","\n","    model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n","    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.2))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(17, activation='sigmoid'))\n","\n","    opt = Adam(lr=1e-4)\n","\n","    model.compile(loss='binary_crossentropy',\n","              # We NEED binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n","              optimizer=opt,\n","              metrics=[multi_label_acc, fbeta])\n","\n","    return model"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[],"source":["#modelcheckpoint is set to monitor the model using validation fbeta score and save the best only\n","save_best_check_point = ModelCheckpoint(filepath = 'best_model.hdf5', monitor = 'val_fbeta', mode = 'max',\n","                                       save_best_only = True, save_weights_only = True)"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 32384 validated image filenames.\n","Found 8095 validated image filenames.\n"]}],"source":["#initializing imagedatagenerator with a validation split of 0.2\n","train_image_gen = ImageDataGenerator(rescale = 1/255, validation_split = 0.2)\n","\n","#generating train data generator which is 80% of the train dataset\n","#note that a generator contains both features and target of the data\n","train_generator = train_image_gen.flow_from_dataframe(dataframe=train_classes1,\n","                                                directory =\"../input/planets-dataset/planet/planet/train-jpg\",  \n","                                                x_col=\"image_name\", y_col=columns, subset=\"training\", \n","                                                batch_size=16,seed=2021, shuffle=True, \n","                                                class_mode=\"raw\", target_size=(128,128))\n","\n","#generating validation data which is expected to be 20% of the train dataset since validation split is 0.2\n","val_generator = train_image_gen.flow_from_dataframe(dataframe=train_classes1,\n","                                                directory =\"../input/planets-dataset/planet/planet/train-jpg\",  \n","                                                x_col=\"image_name\", y_col=columns, subset=\"validation\", \n","                                                batch_size=16,seed=2021, shuffle=True, \n","                                                class_mode=\"raw\", target_size=(128,128))"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["#setting up step size for training and validation image data\n","step_train_size = int(np.ceil(train_generator.samples / train_generator.batch_size))\n","step_val_size = int(np.ceil(val_generator.samples / val_generator.batch_size))"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[],"source":["#initializing the model\n","model1 = build_model()"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","batch_normalization (BatchNo (None, 128, 128, 3)       12        \n","_________________________________________________________________\n","conv2d (Conv2D)              (None, 128, 128, 32)      896       \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 126, 126, 32)      9248      \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 63, 63, 32)        0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 63, 63, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 63, 63, 64)        18496     \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 61, 61, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 30, 30, 64)        0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 30, 30, 128)       73856     \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 28, 28, 128)       147584    \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 14, 14, 128)       0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 14, 14, 128)       0         \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 14, 14, 256)       295168    \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 12, 12, 256)       590080    \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 6, 6, 256)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 9216)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               4719104   \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 17)                8721      \n","=================================================================\n","Total params: 5,900,093\n","Trainable params: 5,900,087\n","Non-trainable params: 6\n","_________________________________________________________________\n"]}],"source":["#this shows the summary of the model, simply put as the model architecture\n","model1.summary()"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/25\n","2024/2024 [==============================] - 136s 67ms/step - loss: 0.2185 - multi_label_acc: 0.9171 - fbeta: 0.7010 - val_loss: 0.1665 - val_multi_label_acc: 0.9353 - val_fbeta: 0.7629\n","Epoch 2/25\n","2024/2024 [==============================] - 109s 54ms/step - loss: 0.1635 - multi_label_acc: 0.9361 - fbeta: 0.7865 - val_loss: 0.1422 - val_multi_label_acc: 0.9441 - val_fbeta: 0.8123\n","Epoch 3/25\n","2024/2024 [==============================] - 109s 54ms/step - loss: 0.1467 - multi_label_acc: 0.9426 - fbeta: 0.8130 - val_loss: 0.1307 - val_multi_label_acc: 0.9483 - val_fbeta: 0.8262\n","Epoch 4/25\n","2024/2024 [==============================] - 109s 54ms/step - loss: 0.1374 - multi_label_acc: 0.9461 - fbeta: 0.8277 - val_loss: 0.1223 - val_multi_label_acc: 0.9532 - val_fbeta: 0.8548\n","Epoch 5/25\n","2024/2024 [==============================] - 109s 54ms/step - loss: 0.1292 - multi_label_acc: 0.9494 - fbeta: 0.8397 - val_loss: 0.1200 - val_multi_label_acc: 0.9530 - val_fbeta: 0.8486\n","Epoch 6/25\n","2024/2024 [==============================] - 109s 54ms/step - loss: 0.1245 - multi_label_acc: 0.9513 - fbeta: 0.8485 - val_loss: 0.1148 - val_multi_label_acc: 0.9556 - val_fbeta: 0.8587\n","Epoch 7/25\n","2024/2024 [==============================] - 109s 54ms/step - loss: 0.1199 - multi_label_acc: 0.9532 - fbeta: 0.8550 - val_loss: 0.1135 - val_multi_label_acc: 0.9568 - val_fbeta: 0.8626\n","Epoch 8/25\n","2024/2024 [==============================] - 109s 54ms/step - loss: 0.1158 - multi_label_acc: 0.9548 - fbeta: 0.8617 - val_loss: 0.1085 - val_multi_label_acc: 0.9580 - val_fbeta: 0.8708\n","Epoch 9/25\n","2024/2024 [==============================] - 109s 54ms/step - loss: 0.1124 - multi_label_acc: 0.9564 - fbeta: 0.8665 - val_loss: 0.1092 - val_multi_label_acc: 0.9586 - val_fbeta: 0.8714\n","Epoch 10/25\n","2024/2024 [==============================] - 110s 54ms/step - loss: 0.1089 - multi_label_acc: 0.9574 - fbeta: 0.8711 - val_loss: 0.1111 - val_multi_label_acc: 0.9569 - val_fbeta: 0.8675\n","Epoch 11/25\n","2024/2024 [==============================] - 110s 54ms/step - loss: 0.1070 - multi_label_acc: 0.9579 - fbeta: 0.8722 - val_loss: 0.1062 - val_multi_label_acc: 0.9591 - val_fbeta: 0.8776\n","Epoch 12/25\n","2024/2024 [==============================] - 109s 54ms/step - loss: 0.1036 - multi_label_acc: 0.9593 - fbeta: 0.8782 - val_loss: 0.1065 - val_multi_label_acc: 0.9590 - val_fbeta: 0.8704\n","Epoch 13/25\n","2024/2024 [==============================] - 109s 54ms/step - loss: 0.1008 - multi_label_acc: 0.9604 - fbeta: 0.8807 - val_loss: 0.1067 - val_multi_label_acc: 0.9590 - val_fbeta: 0.8771\n","Epoch 14/25\n","2024/2024 [==============================] - 109s 54ms/step - loss: 0.0981 - multi_label_acc: 0.9612 - fbeta: 0.8836 - val_loss: 0.1050 - val_multi_label_acc: 0.9598 - val_fbeta: 0.8830\n","Epoch 15/25\n","2024/2024 [==============================] - 109s 54ms/step - loss: 0.0953 - multi_label_acc: 0.9624 - fbeta: 0.8863 - val_loss: 0.1073 - val_multi_label_acc: 0.9594 - val_fbeta: 0.8809\n","Epoch 16/25\n","2024/2024 [==============================] - 110s 54ms/step - loss: 0.0922 - multi_label_acc: 0.9634 - fbeta: 0.8913 - val_loss: 0.1090 - val_multi_label_acc: 0.9597 - val_fbeta: 0.8807\n","Epoch 17/25\n","2024/2024 [==============================] - 108s 53ms/step - loss: 0.0895 - multi_label_acc: 0.9645 - fbeta: 0.8940 - val_loss: 0.1114 - val_multi_label_acc: 0.9596 - val_fbeta: 0.8804\n","Epoch 18/25\n","2024/2024 [==============================] - 108s 53ms/step - loss: 0.0860 - multi_label_acc: 0.9657 - fbeta: 0.8980 - val_loss: 0.1066 - val_multi_label_acc: 0.9600 - val_fbeta: 0.8813\n","Epoch 19/25\n","2024/2024 [==============================] - 108s 53ms/step - loss: 0.0834 - multi_label_acc: 0.9667 - fbeta: 0.9012 - val_loss: 0.1098 - val_multi_label_acc: 0.9600 - val_fbeta: 0.8821\n","Epoch 20/25\n","2024/2024 [==============================] - 108s 53ms/step - loss: 0.0805 - multi_label_acc: 0.9680 - fbeta: 0.9053 - val_loss: 0.1130 - val_multi_label_acc: 0.9597 - val_fbeta: 0.8810\n","Epoch 21/25\n","2024/2024 [==============================] - 108s 53ms/step - loss: 0.0768 - multi_label_acc: 0.9693 - fbeta: 0.9088 - val_loss: 0.1146 - val_multi_label_acc: 0.9585 - val_fbeta: 0.8811\n","Epoch 22/25\n","2024/2024 [==============================] - 108s 54ms/step - loss: 0.0738 - multi_label_acc: 0.9705 - fbeta: 0.9124 - val_loss: 0.1198 - val_multi_label_acc: 0.9600 - val_fbeta: 0.8855\n","Epoch 23/25\n","2024/2024 [==============================] - 110s 54ms/step - loss: 0.0706 - multi_label_acc: 0.9719 - fbeta: 0.9163 - val_loss: 0.1194 - val_multi_label_acc: 0.9605 - val_fbeta: 0.8842\n","Epoch 24/25\n","2024/2024 [==============================] - 109s 54ms/step - loss: 0.0679 - multi_label_acc: 0.9731 - fbeta: 0.9196 - val_loss: 0.1215 - val_multi_label_acc: 0.9598 - val_fbeta: 0.8847\n","Epoch 25/25\n","2024/2024 [==============================] - 110s 54ms/step - loss: 0.0649 - multi_label_acc: 0.9741 - fbeta: 0.9224 - val_loss: 0.1274 - val_multi_label_acc: 0.9594 - val_fbeta: 0.8839\n"]},{"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fb561bb4b50>"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["#fitting our model using the parameters already defined \n","model1.fit(x = train_generator, steps_per_epoch = step_train_size, validation_data = val_generator, \n","           validation_steps = step_val_size,epochs = 25, \n","           callbacks = [save_best_check_point])"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[],"source":["#initializing a second model so we can make predictions\n","model2 = build_model()"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_name</th>\n","      <th>tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>test_0.jpg</td>\n","      <td>primary clear agriculture road water</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>test_1.jpg</td>\n","      <td>primary clear agriculture road water</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>test_2.jpg</td>\n","      <td>primary clear agriculture road water</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>test_3.jpg</td>\n","      <td>primary clear agriculture road water</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>test_4.jpg</td>\n","      <td>primary clear agriculture road water</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   image_name                                  tags\n","0  test_0.jpg  primary clear agriculture road water\n","1  test_1.jpg  primary clear agriculture road water\n","2  test_2.jpg  primary clear agriculture road water\n","3  test_3.jpg  primary clear agriculture road water\n","4  test_4.jpg  primary clear agriculture road water"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["##adding .jpg extension to image name in the sample submission file\n","sample_submission = pd.read_csv('../input/planets-dataset/planet/planet/sample_submission.csv')\n","sample_submission1 = sample_submission.copy()\n","sample_submission1['image_name'] = sample_submission1['image_name'].apply(lambda x: '{}.jpg'.format(x))\n","sample_submission1.head()"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[],"source":["#loading in the weights of the trained model so we can make predictions with it\n","model2.load_weights('best_model.hdf5')"]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>test_0.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>test_1.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>test_2.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>test_3.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>test_4.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   image_name\n","0  test_0.jpg\n","1  test_1.jpg\n","2  test_2.jpg\n","3  test_3.jpg\n","4  test_4.jpg"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["#we divide the sample submission file into two splits, first test1_df which contains the first 40669 images \n","test1_df = sample_submission1.iloc[:40669]['image_name'].reset_index().drop('index', axis =1)\n","test1_df.head()"]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 40669 validated image filenames.\n"]}],"source":["#initializing imagedatagenerator for the test images and also rescaling\n","test_image_gen = ImageDataGenerator(rescale = 1/255)\n","\n","\n","#creating a generator for the images found in the first test image files\n","test_generator1 = test_image_gen.flow_from_dataframe(dataframe=test1_df, \n","                                                directory=\"../input/planets-dataset/planet/planet/test-jpg\", \n","                                                x_col=\"image_name\", y_col=None, batch_size=16, \n","                                                shuffle=False, class_mode=None, target_size=(128,128))\n","\n","step_test_size1 = int(np.ceil(test_generator1.samples/test_generator1.batch_size))"]},{"cell_type":"code","execution_count":23,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2542/2542 [==============================] - 164s 64ms/step\n"]}],"source":["#first, we reset the test generator to avoid shuffling of index as we want it to be orderly\n","test_generator1.reset()\n","pred1 = model2.predict(test_generator1, steps = step_test_size1, verbose = 1)"]},{"cell_type":"code","execution_count":24,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_name</th>\n","      <th>tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>test_0.jpg</td>\n","      <td>clear primary</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>test_1.jpg</td>\n","      <td>clear primary</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>test_2.jpg</td>\n","      <td>partly_cloudy primary</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>test_3.jpg</td>\n","      <td>agriculture clear primary</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>test_4.jpg</td>\n","      <td>partly_cloudy</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   image_name                       tags\n","0  test_0.jpg              clear primary\n","1  test_1.jpg              clear primary\n","2  test_2.jpg      partly_cloudy primary\n","3  test_3.jpg  agriculture clear primary\n","4  test_4.jpg              partly_cloudy"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["#this is to get the filenames in the generator using the attribute .filenames\n","file_names1 = test_generator1.filenames\n","\n","#convert the predicted values to a dataframe and join two labels together if the probability of occurrance \n","#of the label is greater than 0.5 \n","pred_tags1 = pd.DataFrame(pred1)\n","pred_tags1 = pred_tags1.apply(lambda x: ' '.join(np.array(labels)[x>0.5]), axis = 1)\n","\n","#then the result should look like this \n","result1 = pd.DataFrame({'image_name': file_names1, 'tags': pred_tags1})\n","result1.head()"]},{"cell_type":"code","execution_count":25,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>file_0.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>file_1.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>file_10.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>file_100.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>file_1000.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      image_name\n","0     file_0.jpg\n","1     file_1.jpg\n","2    file_10.jpg\n","3   file_100.jpg\n","4  file_1000.jpg"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["#second batch of the test dataset\n","test2_df = sample_submission1.iloc[40669:]['image_name'].reset_index().drop('index', axis =1)\n","test2_df.head()"]},{"cell_type":"code","execution_count":26,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 20522 validated image filenames.\n"]}],"source":["#creating a generator for the second batch of test image files\n","test_generator2 = test_image_gen.flow_from_dataframe(dataframe=test2_df, \n","                                                directory=\"../input/planets-dataset/test-jpg-additional/test-jpg-additional\", \n","                                                x_col=\"image_name\", y_col=None, batch_size=16, \n","                                                shuffle=False, class_mode=None, target_size=(128,128))\n","\n","step_test_size2 = int(np.ceil(test_generator2.samples/test_generator2.batch_size))"]},{"cell_type":"code","execution_count":27,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1283/1283 [==============================] - 83s 65ms/step\n"]}],"source":["#we reset the generator to avoid shuffling, then make prediction on the generator\n","test_generator2.reset()\n","pred2 = model2.predict(test_generator2, steps = step_test_size2, verbose = 1)"]},{"cell_type":"code","execution_count":28,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_name</th>\n","      <th>tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>file_0.jpg</td>\n","      <td>clearprimary</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>file_1.jpg</td>\n","      <td>agriculturepartly_cloudyprimary</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>file_10.jpg</td>\n","      <td>agricultureclearroadwaterprimary</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>file_100.jpg</td>\n","      <td>clearwaterprimary</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>file_1000.jpg</td>\n","      <td>clearprimary</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      image_name                              tags\n","0     file_0.jpg                      clearprimary\n","1     file_1.jpg   agriculturepartly_cloudyprimary\n","2    file_10.jpg  agricultureclearroadwaterprimary\n","3   file_100.jpg                 clearwaterprimary\n","4  file_1000.jpg                      clearprimary"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["#this is to get the filenames in the generator using the attribute .filenames\n","file_names2 = test_generator2.filenames\n","\n","#convert the predicted values to a dataframe and join two labels together if the probability of occurrance \n","#of the label is greater than 0.5\n","pred_tags2 = pd.DataFrame(pred2)\n","pred_tags2 = pred_tags2.apply(lambda x: ''.join(np.array(labels)[x>0.5]), axis = 1)\n","\n","#then the result should look like this\n","result2 = pd.DataFrame({'image_name': file_names2, 'tags': pred_tags2})\n","result2.head()"]},{"cell_type":"code","execution_count":29,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(61191, 2)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_name</th>\n","      <th>tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>test_0.jpg</td>\n","      <td>clear primary</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>test_1.jpg</td>\n","      <td>clear primary</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>test_2.jpg</td>\n","      <td>partly_cloudy primary</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>test_3.jpg</td>\n","      <td>agriculture clear primary</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>test_4.jpg</td>\n","      <td>partly_cloudy</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   image_name                       tags\n","0  test_0.jpg              clear primary\n","1  test_1.jpg              clear primary\n","2  test_2.jpg      partly_cloudy primary\n","3  test_3.jpg  agriculture clear primary\n","4  test_4.jpg              partly_cloudy"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["#for the final result of the predicted tags for the test images, we need to concat the first and second results in \n","#that order to avoid shuffling the index\n","last_result = pd.concat([result1, result2])\n","\n","last_result = last_result.reset_index().drop('index', axis =1)\n","\n","print(last_result.shape)\n","#print the final result\n","last_result.head()"]},{"cell_type":"code","execution_count":30,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_name</th>\n","      <th>tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>test_0</td>\n","      <td>clear primary</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>test_1</td>\n","      <td>clear primary</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>test_2</td>\n","      <td>partly_cloudy primary</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>test_3</td>\n","      <td>agriculture clear primary</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>test_4</td>\n","      <td>partly_cloudy</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  image_name                       tags\n","0     test_0              clear primary\n","1     test_1              clear primary\n","2     test_2      partly_cloudy primary\n","3     test_3  agriculture clear primary\n","4     test_4              partly_cloudy"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["#we need to remove the .jpg extension from the image_name of the last_result because from the sample submission the \n","#extension was not there, we added it for easy manipulation of the data.\n","last_result['image_name'] = last_result['image_name'].apply(lambda x: x[:-4])\n","last_result.head()"]},{"cell_type":"code","execution_count":31,"metadata":{"trusted":true},"outputs":[],"source":["#Finally, we save the result to a csv file using the .to_csv() method and setting the index to false.\n","last_result.to_csv('submission.csv', index = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}
